{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **High Frequency Trading Strategies Design using ML and DL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (8,5) #提前设置图片形状大小\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略一些warnings\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.width', 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features\n",
    "def read_csv(day_trade):\n",
    "    data_up = []\n",
    "    data_down = []\n",
    "    for j,i in enumerate(day_trade):\n",
    "        for k in range(0,len(i),1):\n",
    "            path_up = './processed_data/order_book_3_2014_new' + '_' + str(j+1) + '_' + str(i[k]) + '_' + 'UP' + '.csv'\n",
    "            path_down = './processed_data/order_book_3_2014_new' + '_' + str(j+1) + '_' + str(i[k]) + '_' + 'DOWN' + '.csv'\n",
    "            data_up.append(pd.read_csv(path_up))\n",
    "            data_down.append(pd.read_csv(path_down))\n",
    "    return data_up,data_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './processed_data/order_book_3_2014_new_1_2_UP.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wf/sr17ws052rn9thjq0c5qm_sc0000gp/T/ipykernel_44068/3344471560.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 如果有更多的天数，只用改变日期参数即可\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mday_trade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata_2014_up\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2014_down\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday_trade\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/wf/sr17ws052rn9thjq0c5qm_sc0000gp/T/ipykernel_44068/2226542832.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(day_trade)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mpath_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./processed_data/order_book_3_2014_new'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'UP'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mpath_down\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./processed_data/order_book_3_2014_new'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'DOWN'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mdata_up\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_up\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mdata_down\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_down\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_up\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './processed_data/order_book_3_2014_new_1_2_UP.csv'"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "# 如果有更多的天数，只用改变日期参数即可\n",
    "day_trade = [[2]]\n",
    "data_2014_up, data_2014_down = read_csv(day_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0列是要预测的label\n",
    "\n",
    "# 查看上午的feature数据，第一列为0代表not trade，第一列为1代表trade，后面列都是feature value\n",
    "data_2014_up[0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置需要使用到的ML、DL模型，设置random_state使结果可复制\n",
    "# 可以自行添加更多的分类器，例如MLP，xgboost，软投票分类器等等二分类工具\n",
    "\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state = 0),\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(random_state = 0),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 10,random_state = 0),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(random_state = 0),\n",
    "    'SVC': SVC(probability=True,random_state = 0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置hyperparameter tuning的网格搜索参数\n",
    "\n",
    "model_grid_params = {\n",
    "    'RandomForestClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                               'min_samples_split':[2],'criterion':['entropy'],\\\n",
    "                               'min_samples_leaf':[3]},\n",
    "    'ExtraTreesClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                             'min_samples_split':[2],'criterion':['entropy'],\\\n",
    "                             'min_samples_leaf':[3]},\n",
    "    'AdaBoostClassifier': {\"base_estimator__criterion\" : [\"entropy\"],\\\n",
    "                           \"base_estimator__max_depth\": [None],\\\n",
    "                           \"base_estimator__min_samples_leaf\" : [3],\\\n",
    "                           \"base_estimator__min_samples_split\" : [2],\\\n",
    "                           \"base_estimator__max_features\" : [None]},\n",
    "    'GradientBoostingClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                                   'min_samples_split':[2],'min_samples_leaf':[3],\\\n",
    "                                   'learning_rate':[0.1],'subsample':[1.0]},\n",
    "    'SVC': [{'kernel':['rbf'],'gamma':[1e-1],'C':[1]},\\\n",
    "            {'kernel':['linear'],'C':[1, 10]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Selection Pipline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Selection:\n",
    "    \n",
    "    def __init__(self,models,model_grid_params,data_2014,latest_sec,pred_sec,day):\n",
    "        self.models = models\n",
    "        self.model_grid = model_grid_params\n",
    "        self.data_2014 = data_2014\n",
    "        self.latest_sec = latest_sec\n",
    "        self.pred_sec = pred_sec\n",
    "        self.day = day\n",
    "        self.keys = models.keys()\n",
    "        self.best_score = {}\n",
    "        self.grid = {}\n",
    "        self.predict_values = {}\n",
    "        self.cv_acc = {}\n",
    "        self.acc = {}\n",
    "        self.fscore = {}\n",
    "        self.true_values = {}\n",
    "        self.predict_values_day = {}\n",
    "        self.cv_acc_day = {}\n",
    "        self.acc_day = {}\n",
    "        self.fscore_day = {}\n",
    "        self.true_values_day = {}\n",
    "        self.summary_day = []\n",
    "        \n",
    "    def Grid_fit(self,X_train,y_train,cv = 5,scoring = 'accuracy'):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" %(key))\n",
    "            model = self.models[key]\n",
    "            model_grid = self.model_grid[key]\n",
    "            Grid = GridSearchCV(model, model_grid, cv = cv, scoring = scoring)\n",
    "            Grid.fit(X_train,y_train) \n",
    "            self.grid[key] = Grid\n",
    "            print(Grid.best_params_)\n",
    "            print('CV Best Score = %s'%(Grid.best_score_))\n",
    "            self.cv_acc[key].append(Grid.best_score_)  \n",
    "    \n",
    "    def model_fit(self,X_train, y_train, X_test, y_test):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            print(\"Running training & testing for %s.\" %(key))\n",
    "            model = self.models[key]\n",
    "            # print(self.grid[key].best_params_)\n",
    "            model.set_params(**self.grid[key].best_params_)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            #print 'Prediction latest 15 second = %s'%(predictions)\n",
    "            self.predict_values[key].append(predictions.tolist())\n",
    "            self.true_values[key].append(y_test.tolist())\n",
    "            acc = metrics.accuracy_score(y_test,predictions)\n",
    "            f_score = metrics.f1_score(y_test,predictions)\n",
    "            print('Accuracy = %s'%(acc))\n",
    "            self.acc[key].append(acc)\n",
    "            self.fscore[key].append(f_score)\n",
    "            \n",
    "            if key == 'SVC':\n",
    "                if self.grid[key].best_params_['kernel'] == 'linear':\n",
    "                    feature_imp = dict(zip([i for i in range(0,64,1)],model.coef_[0]))\n",
    "                    Top_five = sorted(feature_imp.items(),key = lambda x : x[1] , reverse=True)[0:5]\n",
    "                    print('Kernel is linear and top five importance features = %s'%(Top_five))\n",
    "                else:\n",
    "                    print('Kernel is rbf')\n",
    "                    pass\n",
    "            else: \n",
    "                feature_imp = dict(zip([i for i in range(0,64,1)],model.feature_importances_))\n",
    "                Top_five = sorted(feature_imp.items(),key = lambda x : x[1] , reverse=True)[0:5]\n",
    "                print('Top five importance features = %s'%(Top_five))\n",
    "                pass\n",
    "\n",
    "    def pipline(self):\n",
    "        \n",
    "        self.set_list_day() # store day values\n",
    "        for day in range(0,self.day,1):\n",
    "            self.set_list() # store values\n",
    "            print('Day = %s'%(day+1))\n",
    "            for i in range(0, 9000-self.latest_sec-600, self.pred_sec):\n",
    "            # for i in range(0, 9000-self.latest_sec-600, self.pred_sec):\n",
    "            # for i in range(0, 200, self.pred_sec):\n",
    "\n",
    "                \n",
    "                print('--------------------Rolling Window Time = %s--------------------'%(i/pred_sec))\n",
    "                # Train data\n",
    "                data_train = self.data_2014[day][i:i+self.latest_sec]\n",
    "                # X_train = data_train.drop(['0'],axis=1)#,'65','66','67'],axis=1)\n",
    "                X_train = data_train.drop(['0','65','66','67'],axis=1)\n",
    "                y_train = data_train['0']\n",
    "\n",
    "                # Test data\n",
    "                data_test = self.data_2014[day][i + self.latest_sec:i + self.latest_sec + self.pred_sec]\n",
    "                # X_test = data_test.drop(['0'],axis=1)#,'65','66','67'],axis=1)\n",
    "                X_test = data_test.drop(['0','65','66','67'],axis=1)\n",
    "                y_test = data_test['0']\n",
    "                \n",
    "                #start = time.time()\n",
    "                self.Grid_fit(X_train, y_train, cv = 5, scoring = 'accuracy')\n",
    "                self.model_fit(X_train, y_train,X_test,y_test)\n",
    "                #end = time.time()\n",
    "                #print 'Total Time = %s'%(end - start)\n",
    "                \n",
    "            for key in self.keys:\n",
    "                \n",
    "                self.cv_acc_day[key].append(self.cv_acc[key])\n",
    "                self.acc_day[key].append(self.acc[key])\n",
    "                self.fscore_day[key].append(self.fscore[key])\n",
    "                self.true_values_day[key].append(self.true_values[key])\n",
    "                self.predict_values_day[key].append(self.predict_values[key])\n",
    "            \n",
    "            self.summary_day.append(self.score_summary(sort_by = 'Accuracy_mean'))\n",
    "    \n",
    "    def set_list(self):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            self.predict_values[key] = []\n",
    "            self.cv_acc[key] = []\n",
    "            self.acc[key] = []\n",
    "            self.fscore[key] = []\n",
    "            self.true_values[key] = []\n",
    "            \n",
    "    def set_list_day(self):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            self.predict_values_day[key] = []\n",
    "            self.cv_acc_day[key] = []\n",
    "            self.acc_day[key] = []\n",
    "            self.fscore_day[key] = []\n",
    "            self.true_values_day[key] = []\n",
    "            \n",
    "    def score_summary(self,sort_by):\n",
    "        \n",
    "        summary = pd.concat([pd.DataFrame(self.acc.keys()),pd.DataFrame(map(lambda x: np.mean(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.std(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.max(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.min(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.mean(self.fscore[x]), self.fscore))],axis=1)\n",
    "        summary.columns = ['Estimator','Accuracy_mean','Accuracy_std','Accuracy_max','Accuracy_min','F_score']\n",
    "        summary.index.rename('Ranking', inplace=True)\n",
    "        return summary.sort_values(by = [sort_by], ascending=False)\n",
    "          \n",
    "    def print_(self):\n",
    "        print(self.predict_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 试运行一组参数\n",
    "# 此处训练集为30min滚动窗口，测试集为未来10s的label值\n",
    "latest_sec = 60 * 30\n",
    "pred_sec = 10\n",
    "data_2014_up, data_2014_down = read_csv(day_trade)\n",
    "day = 1\n",
    "data_2014 = data_2014_up\n",
    "# day=2\n",
    "# data_2014 = data_2014_up + data_2014_down\n",
    "pip = Model_Selection(models,model_grid_params,data_2014,latest_sec,pred_sec,day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型拟合\n",
    "start = time.time()\n",
    "pip.pipline()\n",
    "end = time.time()\n",
    "print('Total Time = %s'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Performance Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip.summary_day[0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip.summary_day[1]#.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip.summary_day[2]#.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Bid and Best Ask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first day\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (14,5))\n",
    "color_ = ['r','b']\n",
    "plt.plot(data_2014[0]['66'],label = 'Best Ask',color = color_[1])\n",
    "plt.plot(data_2014[0]['67'],label = 'Best Bid',color = color_[0])\n",
    "plt.xlim(0, 9000)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time(s)',size = 15)\n",
    "plt.ylabel('Price',size = 15)\n",
    "\n",
    "plt.savefig(\"./images/best_bid_ask.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single Day Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "color = []\n",
    "for key in pip.keys:\n",
    "    plt.plot(np.array(pip.acc_day[key])[0],'-o',label = key,lw = 1,markersize = 3)\n",
    "    plt.legend(loc=0)\n",
    "plt.ylim(-0.5,1.5)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('Accuracy',size = 15)\n",
    "\n",
    "plt.savefig(\"./images/single_day_accuracy.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-Validation Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "color_ = ['r','orange','y','g','b']\n",
    "for index,key in enumerate(pip.keys):\n",
    "    plt.plot(np.array(pip.cv_acc_day[key])[0],'-o',label = key,color = color_[index],lw = 1,markersize = 3)\n",
    "#plot(best_cv_score,'-v',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 6)\n",
    "plt.legend(loc = 0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)\n",
    "plt.savefig(\"./images/CV_result.png\", dpi = 800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtain PnL and Best Cross-Validation Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cum_profit and Best_cv_score\n",
    "dict_ = {}\n",
    "dict_['cum_profit'] = []\n",
    "dict_['Best_cv_score'] = []\n",
    "\n",
    "for day in range(0,1,1):\n",
    "    cum_profit_label = []\n",
    "    cum_profit = []\n",
    "    best_cv_score = []\n",
    "    hold_price = []\n",
    "    true_label = []\n",
    "    predict_label = []\n",
    "    # spread = 0.2 * data_2014[day]['65'][1800:][9::10].values\n",
    "    spread = data_2014[day]['65'][1800:][9::10].values\n",
    "    # loss = 0.2*(data_2014[0]['67'][1800:9000-600][9::10].values - data_2014[day]['67'][1800+600:9000][9::10].values)\n",
    "    # loss = data_2014[0]['67'][1800:9000-600][9::10].values - data_2014[day]['67'][1800+600:9000][9::10].values\n",
    "    loss = -data_2014[day]['65'][1800:][9::10].values\n",
    "    # for j in range(0,len(pip.cv_acc_day.values()[0][day]),1):\n",
    "    for j in range(0,len(pip.cv_acc_day['RandomForestClassifier'][day]),1):\n",
    "    \n",
    "        max_al = {}\n",
    "        for i in range(0,len(pip.keys),1):\n",
    "            max_al[list(pip.keys)[i]] = np.array(pip.cv_acc_day[list(pip.keys)[i]])[day][j]\n",
    "        # select best algorithm in cv = 5    \n",
    "        top_cv_acc = sorted(max_al.items(),key = lambda x : x[1], reverse = True)[0:1][0]\n",
    "        best_cv_score.append(top_cv_acc[1])\n",
    "        submission = pip.predict_values_day[top_cv_acc[0]][day][j][-1]\n",
    "        true_value = pip.true_values_day[top_cv_acc[0]][day][j][-1]\n",
    "        true_label.append(true_value)\n",
    "        predict_label.append(submission)\n",
    "        hold_price.append(data_2014[0]['67'][1800:9000][9::10].values[j])\n",
    "\n",
    "        if submission == true_value:\n",
    "            if submission == 1:\n",
    "                cum_profit_label.append(1)\n",
    "                cum_profit.append(spread[j])\n",
    "            elif submission == 0:\n",
    "                cum_profit_label.append(0)\n",
    "                cum_profit.append(0)\n",
    "        elif submission != true_value:\n",
    "            if submission == 1:\n",
    "                cum_profit_label.append(-1)\n",
    "                cum_profit.append(loss[j])\n",
    "            elif submission == 0:\n",
    "                cum_profit_label.append(0)\n",
    "                cum_profit.append(0)\n",
    "                \n",
    "    dict_['cum_profit'].append(cum_profit)\n",
    "    dict_['Best_cv_score'].append(best_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best CV Score Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cv_score = dict_['Best_cv_score']\n",
    "\n",
    "# 取一部分可视化\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.plot(best_cv_score[0][0:250],'-o',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 5)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)\n",
    "plt.ylim(0.55,1)\n",
    "plt.savefig(\"./images/best_CV_result.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cv_score = dict_['Best_cv_score']\n",
    "\n",
    "# 取全部rolling window可视化\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.plot(best_cv_score[0],'-o',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 5)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)\n",
    "plt.savefig(\"./images/best_CV_result_all.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PnL Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_profit = dict_['cum_profit']\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (14,8))\n",
    "plt.subplot(211)\n",
    "plt.plot(cum_profit[0],'-o',label = 'Profit & Loss (bps)',lw = 1,markersize = 3)\n",
    "plt.ylabel('Tick',size = 15)\n",
    "plt.legend(loc=0)\n",
    "# plt.ylim(-7.5,2.5)\n",
    "plt.subplot(212)\n",
    "plt.plot(np.cumsum(cum_profit[0]),'-o',label = 'Cum Profit (bps)',lw = 1,markersize = 2)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('Profit',size = 15)\n",
    "\n",
    "plt.savefig(\"./images/best_CV_result_all.png\", dpi=800)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total profit in bps\n",
    "cum_profit = dict_['cum_profit']\n",
    "prof = [0] + cum_profit[0]\n",
    "pd.DataFrame(np.cumsum(prof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_price[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"signal\": predict_label, \"close\": hold_price})\n",
    "result['pre_close'] = result['close'].shift()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由交易信号产生实际持仓\n",
    "def position_at_close(df):\n",
    "    \"\"\"\n",
    "    根据signal产生实际持仓。考虑涨跌停不能买入卖出的情况。\n",
    "    所有的交易都是发生在产生信号的K线的结束时\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # ===由signal计算出实际的每天持有仓位\n",
    "    # 在产生signal的k线结束的时候，进行买入\n",
    "    df['signal'].fillna(method='ffill', inplace=True)\n",
    "    df['signal'].fillna(value=0, inplace=True)  # 将初始行数的signal补全为0\n",
    "    df['pos'] = df['signal'].shift()\n",
    "    df['pos'].fillna(value=0, inplace=True)  # 将初始行数的pos补全为0\n",
    "\n",
    "    return df\n",
    "\n",
    "# 计算资金曲线\n",
    "def equity_curve_with_long_at_close(df, c_rate=2.5/10000, t_rate=1.0/1000, slippage=0.01):\n",
    "    \"\"\"\n",
    "    计算股票的资金曲线。只能做多，不能做空。并且只针对满仓操作\n",
    "    每次交易是以当根K线的收盘价为准。\n",
    "    :param df:\n",
    "    :param c_rate: 手续费，commission fees，默认为万分之2.5\n",
    "    :param t_rate: 印花税，tax，默认为千分之1。etf没有\n",
    "    :param slippage: 滑点，股票默认为0.01元，etf为0.001元\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # ==找出开仓、平仓条件\n",
    "    condition1 = df['pos'] != 0\n",
    "    condition2 = df['pos'] != df['pos'].shift(1)\n",
    "    open_pos_condition = condition1 & condition2\n",
    "\n",
    "    condition1 = df['pos'] != 0\n",
    "    condition2 = df['pos'] != df['pos'].shift(-1)\n",
    "    close_pos_condition = condition1 & condition2\n",
    "\n",
    "\n",
    "    # ===基本参数\n",
    "    initial_cash = 10000  # 初始资金，默认为10000元\n",
    "\n",
    "    # ===在买入的K线\n",
    "    # 在发出信号的当根K线以收盘价买入\n",
    "    df.loc[open_pos_condition, 'stock_num'] = initial_cash * (1 - c_rate) / (df['pre_close'] + slippage)\n",
    "\n",
    "    # 买入股票之后剩余的钱，扣除了手续费\n",
    "    df['cash'] = initial_cash - df['stock_num'] * (df['pre_close'] + slippage) * (1 + c_rate)\n",
    "\n",
    "    # 收盘时的股票净值\n",
    "    df['stock_value'] = df['stock_num'] * df['close']\n",
    "\n",
    "    # ===在买入之后的K线\n",
    "    # 买入之后现金不再发生变动\n",
    "    df['cash'].fillna(method='ffill', inplace=True)\n",
    "    df.loc[df['pos'] == 0, ['cash']] = None\n",
    "\n",
    "    # ===在卖出的K线\n",
    "    # 股票数量变动\n",
    "    df.loc[close_pos_condition, 'stock_num'] = df['stock_value'] / df['close']  # 看2006年初\n",
    "\n",
    "    # 现金变动\n",
    "    df.loc[close_pos_condition, 'cash'] += df.loc[close_pos_condition, 'stock_num'] * (df['close'] - slippage) * (\n",
    "                1 - c_rate - t_rate)\n",
    "    # 股票价值变动\n",
    "    df.loc[close_pos_condition, 'stock_value'] = 0\n",
    "\n",
    "    # ===账户净值\n",
    "    df['net_value'] = df['stock_value'] + df['cash']\n",
    "\n",
    "    # ===计算资金曲线\n",
    "    df['equity_change'] = df['net_value'].pct_change(fill_method=None)\n",
    "    df.loc[open_pos_condition, 'equity_change'] = df.loc[open_pos_condition, 'net_value'] / initial_cash - 1  # 开仓日的收益率\n",
    "    df['equity_change'].fillna(value=0, inplace=True)\n",
    "    df['equity_curve'] = (1 + df['equity_change']).cumprod()\n",
    "    df['equity_curve_base'] = (df['close'] / df['pre_close']).cumprod()\n",
    "\n",
    "    # ===删除无关数据\n",
    "    df.drop(['stock_num', 'cash', 'stock_value', 'net_value'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = position_at_close(result)\n",
    "df = equity_curve_with_long_at_close(result1, 0, 0, 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果需要具体的index，哪里发生了最大回撤，那两行，再加上一些robust处理\n",
    "def max_drawdown(X):\n",
    "    X = np.array(X)\n",
    "    try:\n",
    "        i = np.argmin((X - np.maximum.accumulate(X))/np.maximum.accumulate(X))\n",
    "        j = np.argmax(X[:i])\n",
    "        return i, j, (X[i]-X[j])/X[j]\n",
    "    except:\n",
    "        return 0\n",
    "max_drawdown(df['equity_curve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算累积收益, exp_rate为业绩报酬率\n",
    "def cum_return(X: pd.Series, exp_rate=0):\n",
    "    X = np.array(X)\n",
    "    t = (X[-1]-X[0])/X[0]\n",
    "    if t > 0:\n",
    "        return t * (1-exp_rate)\n",
    "    else:\n",
    "        return t\n",
    "cum_return(df['equity_curve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More: Develop the effect of training window period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sec = 10\n",
    "data_2014_up, data_2014_down = read_csv(day_trade)\n",
    "day = 1\n",
    "data_2014 = data_2014_up\n",
    "# day=2\n",
    "# data_2014 = data_2014_up+ data_2014_down\n",
    "\n",
    "color_ = ['r','orange','y','g','b']\n",
    "\n",
    "x = []\n",
    "y = {'RandomForestClassifier': [],\n",
    " 'ExtraTreesClassifier': [],\n",
    " 'AdaBoostClassifier': [],\n",
    " 'GradientBoostingClassifier': [],\n",
    " 'SVC': []}\n",
    "\n",
    "for latest_sec in range(10, 660,2):\n",
    "    pip = Model_Selection(models,model_grid_params,data_2014,latest_sec,pred_sec,day)\n",
    "    pip.pipline()\n",
    "    x.append(latest_sec)\n",
    "    for index,key in enumerate(pip.keys):\n",
    "        y[key].append(pip.cv_acc_day[key][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.ylim(0.6, 1)\n",
    "plt.xlim(0, 700)\n",
    "for index,key in enumerate(pip.keys):\n",
    "    plt.plot(x, y[key],'-o',label = key ,color = color_[index], lw = 1, markersize = 2)\n",
    "    # plot(best_cv_score,'-v',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 6)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Training Sliding Window',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
